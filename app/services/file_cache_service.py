"""
æ–‡ä»¶ç¼“å­˜æœåŠ¡ - åˆ†ç‰‡æ–‡ä»¶ç³»ç»Ÿç¼“å­˜
"""

import os
import json
import hashlib
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from app.config.config import get_settings


class FileCacheService:
    """æ–‡ä»¶ç¼“å­˜æœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ–‡ä»¶ç¼“å­˜æœåŠ¡"""
        # ä»é…ç½®æ–‡ä»¶è¯»å–è®¾ç½®
        self.settings = get_settings()

        self.cache_dir = "cache/translations"
        self.index_file = "cache/index/cache_index.json"
        self.cache_ttl_days = self.settings.file_cache_ttl_days
        self.max_size_mb = self.settings.file_cache_max_size_mb
        self.cleanup_interval_hours = self.settings.file_cache_cleanup_interval_hours

        # ä¸­æ–‡è½¬å…¶ä»–9ç§è¯­è¨€æ˜ å°„
        self.source_language = "zh"  # å›ºå®šæºè¯­è¨€ä¸ºä¸­æ–‡
        self.target_languages = {
            "en": "english",      # è‹±è¯­
            "ms": "malay",        # é©¬æ¥è¯­
            "km": "khmer",        # é«˜æ£‰è¯­
            "id": "indonesian",   # å°å°¼è¯­
            "my": "myanmar",      # ç¼…ç”¸è¯­
            "fil": "filipino",    # è²å¾‹å®¾è¯­
            "th": "thai",         # æ³°è¯­
            "vi": "vietnamese",   # è¶Šå—è¯­
            "ta": "tamil",        # æ³°ç±³å°”è¯­
            "lo": "lao"           # è€æŒè¯­
        }

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.cache_dir, exist_ok=True)
        os.makedirs(os.path.dirname(self.index_file), exist_ok=True)

        # åˆ›å»ºè¯­è¨€å¯¹ç›®å½•
        self.create_language_directories()

        # åŠ è½½ç´¢å¼•
        self.cache_index = self.load_index()

        print(f"ğŸ“ æ–‡ä»¶ç¼“å­˜æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        print(f"  ç¼“å­˜ç›®å½•: {self.cache_dir}")
        print(f"  ç´¢å¼•æ–‡ä»¶: {self.index_file}")
        print(f"  ç¼“å­˜TTL: {self.cache_ttl_days}å¤© (æ¥è‡ªé…ç½®)")
        print(f"  æœ€å¤§ç¼“å­˜å¤§å°: {self.max_size_mb}MB (æ¥è‡ªé…ç½®)")
        print(f"  æ¸…ç†é—´éš”: {self.cleanup_interval_hours}å°æ—¶ (æ¥è‡ªé…ç½®)")
        print(f"  æºè¯­è¨€: ä¸­æ–‡ (zh)")
        print(f"  ç›®æ ‡è¯­è¨€: {len(self.target_languages)}ç§")
        print(f"  ç›®æ ‡è¯­è¨€åˆ—è¡¨: {', '.join(self.target_languages.values())}")

    def create_language_directories(self):
        """åˆ›å»ºä¸­æ–‡è½¬å…¶ä»–è¯­è¨€çš„ç¼“å­˜ç›®å½•ç»“æ„"""
        print("ğŸ“‚ åˆ›å»ºä¸­æ–‡è½¬å…¶ä»–è¯­è¨€ç¼“å­˜ç›®å½•...")

        # åªåˆ›å»ºä¸­æ–‡è½¬å…¶ä»–è¯­è¨€çš„ç›®å½•
        for target_code, target_name in self.target_languages.items():
            # åˆ›å»ºè¯­è¨€ç›®å½•ï¼šchinese-english, chinese-malay ç­‰
            lang_dir = os.path.join(
                self.cache_dir,
                f"chinese-{target_name}"
            )
            os.makedirs(lang_dir, exist_ok=True)

            # åœ¨è¯­è¨€ç›®å½•ä¸‹åˆ›å»ºå“ˆå¸Œåˆ†ç‰‡ç›®å½•
            for i in range(16):  # 00-0f
                for j in range(16):  # 00-0f
                    hash_dir = os.path.join(lang_dir, f"{i:02x}", f"{j:02x}")
                    os.makedirs(hash_dir, exist_ok=True)

        print(f"âœ… å·²åˆ›å»º {len(self.target_languages)} ä¸ªä¸­æ–‡è½¬å…¶ä»–è¯­è¨€ç›®å½•")

    def get_language_pair_name(self, source_lang: str, target_lang: str) -> str:
        """è·å–è¯­è¨€å¯¹åç§° - åªæ”¯æŒä¸­æ–‡è½¬å…¶ä»–è¯­è¨€"""
        if source_lang != "zh":
            raise ValueError(f"åªæ”¯æŒä¸­æ–‡(zh)ä½œä¸ºæºè¯­è¨€ï¼Œå½“å‰æºè¯­è¨€: {source_lang}")

        target_name = self.target_languages.get(target_lang)
        if not target_name:
            raise ValueError(f"ä¸æ”¯æŒçš„ç›®æ ‡è¯­è¨€: {target_lang}ï¼Œæ”¯æŒçš„è¯­è¨€: {list(self.target_languages.keys())}")

        return f"chinese-{target_name}"

    def normalize_path(self, path: str) -> str:
        """æ ‡å‡†åŒ–è·¯å¾„"""
        # ç§»é™¤æŸ¥è¯¢å‚æ•°å’Œé”šç‚¹
        if '?' in path:
            path = path.split('?')[0]
        if '#' in path:
            path = path.split('#')[0]

        # æ ‡å‡†åŒ–æ–œæ å’Œå¤§å°å†™
        path = path.lower().rstrip('/')

        return path

    def generate_cache_key(self, path: str, source_lang: str, target_lang: str) -> str:
        """ç”ŸæˆåŸºäºè·¯å¾„çš„MD5ç¼“å­˜é”®"""
        # æ ‡å‡†åŒ–è·¯å¾„
        normalized_path = self.normalize_path(path)

        # ç»„åˆè·¯å¾„å’Œè¯­è¨€å¯¹
        content = f"{normalized_path}|{source_lang}|{target_lang}"

        # ç”ŸæˆMD5å“ˆå¸Œå¹¶æˆªå–12ä½
        return hashlib.md5(content.encode('utf-8')).hexdigest()[:12]
    
    def get_cache_file_path(self, cache_key: str, source_lang: str, target_lang: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„ - æŒ‰è¯­è¨€å¯¹å’Œå“ˆå¸Œåˆ†ç‰‡"""
        # è·å–è¯­è¨€å¯¹åç§°
        lang_pair = self.get_language_pair_name(source_lang, target_lang)

        # åˆ†ç‰‡ç­–ç•¥ï¼šè¯­è¨€å¯¹/å‰2ä½/ç¬¬3-4ä½/å®Œæ•´å“ˆå¸Œ.json
        return os.path.join(
            self.cache_dir,
            lang_pair,
            cache_key[:2],
            cache_key[2:4],
            f"{cache_key}.json"
        )
    
    def load_index(self) -> Dict:
        """åŠ è½½ç¼“å­˜ç´¢å¼•"""
        if os.path.exists(self.index_file):
            try:
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def save_index(self):
        """ä¿å­˜ç¼“å­˜ç´¢å¼•"""
        try:
            with open(self.index_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache_index, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")
    
    def is_cache_expired(self, cache_data: Dict) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ"""
        try:
            expires_at = datetime.fromisoformat(cache_data["metadata"]["expires_at"])
            return datetime.now() > expires_at
        except:
            return True
    
    async def get_cache(self, path: str, source_lang: str, target_lang: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜"""
        try:
            # 1. ç”ŸæˆåŸºäºè·¯å¾„çš„ç¼“å­˜é”®
            cache_key = self.generate_cache_key(path, source_lang, target_lang)
            
            # 2. æ£€æŸ¥ç´¢å¼•
            if cache_key in self.cache_index:
                cache_info = self.cache_index[cache_key]
                file_path = cache_info["file_path"]
                
                # 3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(file_path):
                    # 4. åŠ è½½ç¼“å­˜æ•°æ®
                    with open(file_path, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    
                    # 5. æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                    if not self.is_cache_expired(cache_data):
                        print(f"âœ… æ–‡ä»¶ç¼“å­˜å‘½ä¸­: {cache_key[:8]}...")
                        return cache_data["content"]
                    else:
                        print(f"â° æ–‡ä»¶ç¼“å­˜å·²è¿‡æœŸ: {cache_key[:8]}...")
                        # åˆ é™¤è¿‡æœŸç¼“å­˜
                        await self.delete_cache_file(cache_key, file_path)
                else:
                    print(f"ğŸ“ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_key[:8]}...")
                    # ä»ç´¢å¼•ä¸­åˆ é™¤æ— æ•ˆæ¡ç›®
                    del self.cache_index[cache_key]
                    self.save_index()
            
            print(f"âŒ æ–‡ä»¶ç¼“å­˜æœªå‘½ä¸­: {cache_key[:8]}...")
            return None
            
        except Exception as e:
            print(f"âŒ è·å–æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    async def set_cache(self, path: str, source_lang: str, target_lang: str, translation_result: Dict) -> bool:
        """è®¾ç½®ç¼“å­˜"""
        try:
            # 1. ç”ŸæˆåŸºäºè·¯å¾„çš„ç¼“å­˜é”®
            cache_key = self.generate_cache_key(path, source_lang, target_lang)
            
            # 2. è·å–æ–‡ä»¶è·¯å¾„
            file_path = self.get_cache_file_path(cache_key, source_lang, target_lang)
            
            # 3. åˆ›å»ºç›®å½•
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # 4. å‡†å¤‡ç¼“å­˜æ•°æ®
            cache_data = {
                "metadata": {
                    "cache_key": cache_key,
                    "created_at": datetime.now().isoformat(),
                    "expires_at": (datetime.now() + timedelta(days=self.cache_ttl_days)).isoformat(),
                    "source_lang": source_lang,
                    "target_lang": target_lang,
                    "path": path,
                    "file_path": file_path,
                    "cache_method": "path_hash_md5"
                },
                "content": translation_result
            }
            
            # 5. ä¿å­˜ç¼“å­˜æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False)
            
            # 6. æ›´æ–°ç´¢å¼•
            self.cache_index[cache_key] = {
                "file_path": file_path,
                "created_at": cache_data["metadata"]["created_at"],
                "expires_at": cache_data["metadata"]["expires_at"],
                "path": path,
                "source_lang": source_lang,
                "target_lang": target_lang,
                "cache_method": "path_hash_md5"
            }
            self.save_index()
            
            print(f"ğŸ’¾ æ–‡ä»¶ç¼“å­˜å·²ä¿å­˜: {cache_key[:8]}...")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    async def delete_cache_file(self, cache_key: str, file_path: str):
        """åˆ é™¤ç¼“å­˜æ–‡ä»¶"""
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
            
            if cache_key in self.cache_index:
                del self.cache_index[cache_key]
                self.save_index()
                
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤è¿‡æœŸç¼“å­˜: {cache_key[:8]}...")
        except Exception as e:
            print(f"âŒ åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            total_files = len(self.cache_index)
            total_size = 0
            language_pairs = {}

            for cache_info in self.cache_index.values():
                file_path = cache_info["file_path"]
                if os.path.exists(file_path):
                    total_size += os.path.getsize(file_path)

                    # ç»Ÿè®¡è¯­è¨€å¯¹
                    source_lang = cache_info.get("source_lang", "unknown")
                    target_lang = cache_info.get("target_lang", "unknown")
                    lang_pair = self.get_language_pair_name(source_lang, target_lang)
                    language_pairs[lang_pair] = language_pairs.get(lang_pair, 0) + 1

            return {
                "status": "active",
                "total_files": total_files,
                "total_size_mb": round(total_size / 1024 / 1024, 2),
                "cache_dir": self.cache_dir,
                "config": {
                    "ttl_days": self.cache_ttl_days,
                    "max_size_mb": self.max_size_mb,
                    "cleanup_interval_hours": self.cleanup_interval_hours,
                    "config_source": ".envæ–‡ä»¶"
                },
                "source_language": "chinese (zh)",
                "supported_target_languages": len(self.target_languages),
                "language_directories": language_pairs,
                "target_languages": self.target_languages
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }


# åˆ›å»ºå…¨å±€å®ä¾‹
file_cache_service = FileCacheService()
